{"cells":[{"cell_type":"markdown","metadata":{"id":"YSbtUgtcWsHc"},"source":["# Logical Reasoning using Transformers with Dependency Parsed Input\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"executionInfo":{"elapsed":7676,"status":"error","timestamp":1639173798216,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"},"user_tz":300},"id":"3HZ_AusSWp7m","outputId":"ec41345a-b3f6-4965-8324-8c33d27b68f8"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 136\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"J9aRClrXYfHv"},"source":["Setting up GPU"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":288,"status":"ok","timestamp":1639093771801,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"},"user_tz":300},"id":"wOD0AYCbYdlF","outputId":"553efee3-76e1-4783-c704-3f92c62fad01"},"outputs":[{"name":"stdout","output_type":"stream","text":["Thu Dec  9 23:49:31 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   40C    P0    32W / 250W |   4897MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GrSiTjIeXaFn"},"source":["Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62441,"status":"ok","timestamp":1639093835854,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"},"user_tz":300},"id":"dN0fYjnBWmx-","outputId":"9df647db-8154-438a-fd1c-a718317339fa"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n"]}],"source":["import os\n","import json\n","#import torch\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","\n","drive_path = '/content/drive/MyDrive/FinalProject/'\n","\n","# inputs is question and context and concatenated answer, one output as confidence\n","\n","def load_data(path, test):\n","    dict = {\n","        'prompt': [],\n","        'label': []\n","    }\n","    input = pd.DataFrame(dict)\n","    f = open(path)\n","    data = json.load(f)\n","    iterator = 0\n","    for d in data['context']:\n","      prompt = '[CLS]' + data['context'][str(iterator)] + '[SEP]' + data['question'][str(iterator)] + '[DEP]' + data['dep_context'][str(iterator)] + '[SEP]'\n","      for a in range(4):\n","        answer = data['answers'][str(iterator)][a] + '[DEP]' + data['dep_answers'][str(iterator)][a]\n","        concatenated_dp = prompt + answer\n","        label = 0\n","        if not test and a == data['label'][str(iterator)]:\n","          label = [1]\n","        else:\n","          label = [0]\n","        input.loc[len(input.index)] = [concatenated_dp, label]\n","      iterator += 1\n","    return input\n","train_data = load_data(drive_path + 'reclor_data_with_dependencies/train.json', False)\n","val_data = load_data(drive_path + 'reclor_data_with_dependencies/val.json', False)\n","test_data = load_data(drive_path + 'reclor_data_with_dependencies/test.json', True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2651,"status":"ok","timestamp":1639090133712,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"},"user_tz":300},"id":"-225CZImmz8w","outputId":"c840d3c4-5036-48c2-881a-9ea97add5541"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.13.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.2.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"]}],"source":["!pip install transformers"]},{"cell_type":"markdown","metadata":{"id":"QewmF4FjXdMI"},"source":["Initialize tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2587,"status":"ok","timestamp":1639093838428,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"},"user_tz":300},"id":"6FifoAfYWmyC","outputId":"a62299d6-e2e0-4324-aa58-cb7db15b68fd"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["from transformers import RobertaTokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', \n","                                             unk_token='[UNK]', \n","                                             sep_token='[SEP]', \n","                                             pad_token='[PAD]',\n","                                             cls_token='[CLS]',\n","                                             bos_token='[CLS]')\n","\n","special_tokens_dict = {'additional_special_tokens': ['[DEP]']}\n","num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n"]},{"cell_type":"markdown","metadata":{"id":"ST4vzaugXe3F"},"source":["Tokenize the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_IwKvRzrWmyD"},"outputs":[],"source":["import torch\n","from tqdm import tqdm\n","from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n","\n","max_len = 512\n","batch_size = 1\n","\n","def preprocess(input, tokenizer, max_len, batch_size, data_class='train'):\n","    encoded_input = tokenizer(input['prompt'].values.tolist(), padding=True, max_length = max_len, truncation = True, return_tensors=\"pt\")\n","    \n","    input_ids = encoded_input['input_ids']\n","    attention_mask = encoded_input['attention_mask']\n","    \n","    if data_class != 'test':\n","        labels = torch.tensor(input['label'].values.tolist())\n","    dataset_tensor = TensorDataset(input_ids, attention_mask, labels)\n","    \n","    if data_class == \"train\":\n","        sampler = RandomSampler(dataset_tensor)\n","    else:\n","        sampler = SequentialSampler(dataset_tensor)\n","    dataloader = DataLoader(dataset_tensor, sampler=sampler, batch_size=batch_size)\n","    \n","    return dataloader\n","\n","train_dataloader = preprocess(train_data, tokenizer, max_len, batch_size, data_class=\"train\")\n","val_dataloader = preprocess(val_data, tokenizer, max_len, batch_size, data_class=\"val\")\n","#test_dataloader = preprocess(test_data, tokenizer, max_len, batch_size, data_class=\"test\")"]},{"cell_type":"markdown","metadata":{"id":"BdmnMX7OXhRJ"},"source":["Train and Eval"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"t-Uf7cPZWmyE","outputId":"154f00de-bd94-485f-c79b-f586bbd11cd6"},"outputs":[{"name":"stdout","output_type":"stream","text":["RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.13.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Start Training!\n","\n","Epoch 0\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 18552/18552 [1:21:58<00:00,  3.77it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Train loss on epoch 0: 0.5700470470735396\n","\n","Evaluate on the dev set:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2000/2000 [05:14<00:00,  6.35it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy: 0.0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from transformers import RobertaConfig, RobertaForSequenceClassification, AdamW\n","\n","\n","def Eval(model, dataloader):\n","    model.eval()\n","    predictions, true_labels = [], []\n","    num_correct = 0\n","\n","    for step, batch in enumerate(tqdm(dataloader)):\n","        input_ids, attention_mask, labels = batch[0], batch[1], batch[2]\n","        outputs = model(input_ids.cuda(), attention_mask = attention_mask.cuda(), labels=labels.cuda())\n","\n","        logits = outputs.logits\n","        label_ids = labels.numpy()\n","\n","        temp = torch.nn.functional.softmax(logits, dim=1).topk(1, dim = 1).indices.flatten().tolist()\n","\n","        predictions.extend(temp)\n","        true_labels.extend(labels.tolist())\n","\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","    \n","    for i in range(len(predictions)):\n","        if predictions[i] == true_labels[i]:\n","            num_correct += 1\n","    \n","    print(\"\\nAccuracy: %s\" % (float(num_correct) / float(len(true_labels))))\n","\n","def Train(model, train_data, lr, n_epoch, dev_data):\n","    print(\"Start Training!\")\n","    optimizer = AdamW(model.parameters(), lr=lr)\n","\n","    # TRAIN loop\n","    for epoch in range(n_epoch):  \n","\n","        print(f\"\\nEpoch {epoch}\")\n","      \n","        model.train()\n","        tr_loss = 0\n","        nb_tr_examples, nb_tr_steps = 0, 0\n","\n","        for step, batch in enumerate(tqdm(train_data)):\n","            #TODO: Implement BERT fine-tuning.\n","            optimizer.zero_grad()\n","\n","            #print(batch[0])\n","            input_ids = batch[0].cuda()\n","            attention_mask = batch[1].cuda()\n","            labels = batch[2].cuda()\n","\n","            outputs = model(input_ids, attention_mask = attention_mask, labels = labels)\n","            outputs.loss.backward()\n","            optimizer.step()\n","            tr_loss += float(outputs.loss)\n","\n","            torch.cuda.empty_cache()\n","            gc.collect()\n","            nb_tr_steps += 1\n","\n","    # print train loss per epoch\n","    print(\"Train loss on epoch {}: {}\\n\".format(epoch, tr_loss / nb_tr_steps))\n","\n","    # Dev set evaluation\n","    print(\"Evaluate on the dev set:\")\n","    Eval(model, dev_data)\n","\n","import gc\n","\n","config = RobertaConfig.from_pretrained('roberta-base')\n","print(config)\n","model = RobertaForSequenceClassification.from_pretrained('roberta-base', config=config)\n","model.resize_token_embeddings(len(tokenizer))\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","\n","learning_rate = 2e-5\n","num_epoch = 1\n","\n","torch.no_grad()\n","\n","torch.cuda.empty_cache()\n","gc.collect()\n","\n","if n_gpu > 1:\n","    model.to(device)\n","    model = torch.nn.DataParallel(model)\n","else:\n","    model.cuda()\n","\n","Train(model, train_dataloader, learning_rate, num_epoch, val_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82533,"status":"ok","timestamp":1639093301426,"user":{"displayName":"elbowroom","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16478181345569282121"},"user_tz":300},"id":"1aFBpmjZfKh8","outputId":"01943602-da79-401a-a33c-3d6d0b4b42cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluate on the dev set:\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 500/500 [01:22<00:00,  6.07it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Accuracy: 0.0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["print(\"Evaluate on the dev set in test taking form:\")\n","def EvalTest(model, dataloader):\n","    model.eval()\n","    predictions, true_labels = [], []\n","    num_correct = 0\n","    \n","    for step, batch in enumerate(tqdm(dataloader)):\n","        input_ids, attention_mask, labels = batch[0], batch[1], batch[2]\n","        outputs = model(input_ids.cuda(), attention_mask = attention_mask.cuda(), labels=labels.cuda())\n","\n","        logits = outputs.logits\n","        label_ids = labels.numpy()\n","\n","        temp = torch.nn.functional.softmax(logits, dim=1).topk(1, dim = 1).indices.flatten().tolist()\n","\n","        predictions.extend(temp)\n","        true_labels.extend(labels.tolist())\n","\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","    \n","    for i in range(len(predictions)):\n","        if predictions[i] == true_labels[i]:\n","            num_correct += 1\n","    \n","    print(\"\\nAccuracy: %s\" % (float(num_correct) / float(len(true_labels))))\n","EvalTest(model, val_dataloader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1DRS_H0_WmyF","outputId":"9ec0939b-c810-49f6-a534-080bca89eb34"},"outputs":[{"data":{"text/plain":["tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         1, 1, 1, 1, 1, 1, 1, 1]])"]},"execution_count":null,"metadata":{},"output_type":"execute_result"}],"source":["next(iter(val_dataloader))[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ORNlg-zUCtpD"},"outputs":[],"source":["for t in iter(train_dataloader):\n","  print(t[1].shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psYAZMAVDLVa"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"Roberta.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}